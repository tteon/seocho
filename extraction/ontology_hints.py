"""
Ontology hint loader for semantic query-time disambiguation.

The file is optional and expected to be generated by offline ontology jobs.
Default path: output/ontology_hints.json
"""

from __future__ import annotations

import json
import logging
import os
import re
from typing import Dict, List, Set

logger = logging.getLogger(__name__)


def _normalize(value: str) -> str:
    return re.sub(r"[^a-z0-9]+", " ", value.lower()).strip()


class OntologyHintStore:
    """In-memory ontology hint store with lightweight alias/label maps."""

    def __init__(self, path: str = "output/ontology_hints.json"):
        self.path = path
        self.aliases: Dict[str, str] = {}
        self.label_keywords: Dict[str, Set[str]] = {}
        self.loaded: bool = False
        self.load()

    def load(self) -> None:
        self.aliases = {}
        self.label_keywords = {}
        self.loaded = False

        if not self.path or not os.path.exists(self.path):
            logger.info("Ontology hints file not found: %s", self.path)
            return

        try:
            with open(self.path, "r", encoding="utf-8") as handle:
                payload = json.load(handle)
        except Exception as exc:
            logger.warning("Failed to load ontology hints (%s): %s", self.path, exc)
            return

        alias_map = payload.get("aliases", {})
        if isinstance(alias_map, dict):
            for src, dst in alias_map.items():
                src_norm = _normalize(str(src))
                dst_text = str(dst).strip()
                if src_norm and dst_text:
                    self.aliases[src_norm] = dst_text

        label_map = payload.get("label_keywords", {})
        if isinstance(label_map, dict):
            for label, keywords in label_map.items():
                label_key = _normalize(str(label))
                if not label_key:
                    continue
                bucket: Set[str] = set()
                if isinstance(keywords, list):
                    for keyword in keywords:
                        token = _normalize(str(keyword))
                        if token:
                            bucket.add(token)
                if bucket:
                    self.label_keywords[label_key] = bucket

        self.loaded = bool(self.aliases or self.label_keywords)
        logger.info(
            "Loaded ontology hints: aliases=%d label_groups=%d",
            len(self.aliases),
            len(self.label_keywords),
        )

    def resolve_alias(self, entity_text: str) -> str:
        key = _normalize(entity_text)
        return self.aliases.get(key, entity_text)

    def infer_label_hints(self, question: str) -> Set[str]:
        q_norm = _normalize(question)
        hits: Set[str] = set()
        if not q_norm:
            return hits

        for label, keywords in self.label_keywords.items():
            if any(keyword in q_norm for keyword in keywords):
                hits.add(label)
        return hits

    def to_summary(self) -> Dict[str, object]:
        return {
            "path": self.path,
            "loaded": self.loaded,
            "alias_count": len(self.aliases),
            "label_group_count": len(self.label_keywords),
        }

