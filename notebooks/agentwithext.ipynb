{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "kgcandid=pd.read_csv('kgresults.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# 1. Check if we are in Docker\n",
    "in_docker = os.path.exists('/.dockerenv')\n",
    "print(f\"ğŸ³ Running inside Docker? {'YES' if in_docker else 'NO'}\")\n",
    "\n",
    "# 2. Hostname Resolution Test\n",
    "print(\"\\n--- DNS Resolution ---\")\n",
    "for host in ['neo4j', 'graphrag-neo4j', 'localhost']:\n",
    "    try:\n",
    "        ip = socket.gethostbyname(host)\n",
    "        print(f\"âœ… {host} -> {ip}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ {host} -> FAILED ({e})\")\n",
    "\n",
    "# 3. Connection Test\n",
    "print(\"\\n--- Neo4j Connection ---\")\n",
    "if in_docker:\n",
    "    # In Docker, we MUST use the service name 'neo4j' or 'graphrag-neo4j'\n",
    "    target = 'neo4j'\n",
    "else:\n",
    "    # Local, we MUST use localhost\n",
    "    target = 'localhost'\n",
    "\n",
    "uri = f\"bolt://{target}:7687\"\n",
    "print(f\"Attempting connection to {uri}...\")\n",
    "\n",
    "try:\n",
    "    auth = (os.getenv('NEO4J_USER', 'neo4j'), os.getenv('NEO4J_PASSWORD', 'password'))\n",
    "    driver = GraphDatabase.driver(uri, auth=auth)\n",
    "    driver.verify_connectivity()\n",
    "    print(\"ğŸ‰ SUCCESS! Connected.\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ CONNECTION FAILED: {e}\")\n",
    "    \n",
    "    print(\"\\n--- TROUBLESHOOTING GUIDE ---\")\n",
    "    if in_docker:\n",
    "        print(\"1. If 'neo4j' DNS failed: The containers might not be on the same network named 'graphrag-net'.\")\n",
    "        print(\"2. If DNS works but Connection Refused: Neo4j container is running but not listening (starting up or crashed).\")\n",
    "    else:\n",
    "        print(\"1. You are running LOCALLY. Ensure 'docker-compose up' is running successfully in another terminal.\")\n",
    "        print(\"2. Check if Neo4j is actually running: 'docker ps' | grep neo4j'\")\n",
    "        print(\"3. Check Neo4j logs: 'docker logs graphrag-neo4j' (Look for 'Started' message)\")\n",
    "        print(\"4. If logs say 'Plugin failure', the open-gds.jar might be missing/corrupt in data/neo4j/plugins.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [í•µì‹¬] ì‹¤í—˜ ëª¨ë“œ vs íƒ€ê²Ÿ ë°ì´í„°ë² ì´ìŠ¤ ë§µí•‘\n",
    "# format: 'csv_mode_name': 'neo4j_database_name'\n",
    "DB_MAPPING = {\n",
    "    \"BASELINE\": \"kgnormal\",\n",
    "    \"FIBO\": \"kgfibo\"\n",
    "}\n",
    "\n",
    "# ==========================================\n",
    "# 2. íŒŒì‹± í—¬í¼\n",
    "# ==========================================\n",
    "def parse_record(record_str):\n",
    "    try:\n",
    "        if isinstance(record_str, str):\n",
    "            return ast.literal_eval(record_str)\n",
    "        return record_str\n",
    "    except (ValueError, SyntaxError):\n",
    "        return {}\n",
    "\n",
    "# ==========================================\n",
    "# 3. íŠ¹ì • DBë¡œ ì ì¬í•˜ëŠ” í•¨ìˆ˜\n",
    "# ==========================================\n",
    "def ingest_to_specific_db(driver, df, mode, target_db):\n",
    "    print(f\"\\nğŸš€ [Mode: {mode}] -> [DB: {target_db}] ì ì¬ ì‹œì‘ (ì´ {len(df)}ê±´)\")\n",
    "    \n",
    "    # ì¿¼ë¦¬: ë…¸ë“œ ìƒì„±\n",
    "    node_query = \"\"\"\n",
    "    UNWIND $batch AS row\n",
    "    MERGE (e:Entity {name: row.text})\n",
    "    ON CREATE SET e.type = row.type, e.source_mode = $mode\n",
    "    \"\"\"\n",
    "    \n",
    "    # âš ï¸ í•µì‹¬ ë³€ê²½ ì‚¬í•­: session ìƒì„± ì‹œ database ì§€ì •\n",
    "    try:\n",
    "        with driver.session(database=target_db) as session:\n",
    "            \n",
    "            # --- [Step 1] ë…¸ë“œ ì ì¬ ---\n",
    "            batch_nodes = []\n",
    "            for _, row in df.iterrows():\n",
    "                parsed_ent = parse_record(row['extracted_entities'])\n",
    "                entities = parsed_ent.get('extracted_entities', [])\n",
    "                batch_nodes.extend(entities)\n",
    "                \n",
    "                if len(batch_nodes) >= 1000:\n",
    "                    session.run(node_query, batch=batch_nodes, mode=mode)\n",
    "                    batch_nodes = []\n",
    "            \n",
    "            if batch_nodes:\n",
    "                session.run(node_query, batch=batch_nodes, mode=mode)\n",
    "            print(f\"   âœ… ë…¸ë“œ ìƒì„± ì™„ë£Œ (@{target_db})\")\n",
    "\n",
    "            # --- [Step 2] ê´€ê³„ ì ì¬ ---\n",
    "            rels_by_type = {}\n",
    "            for _, row in df.iterrows():\n",
    "                parsed_rel = parse_record(row['linked_relationships'])\n",
    "                relationships = parsed_rel.get('entity_relationships', [])\n",
    "                \n",
    "                for rel in relationships:\n",
    "                    r_type = rel['relation_type'].strip().upper().replace(\" \", \"_\")\n",
    "                    if not r_type: continue\n",
    "                    \n",
    "                    if r_type not in rels_by_type:\n",
    "                        rels_by_type[r_type] = []\n",
    "                    \n",
    "                    rels_by_type[r_type].append({\n",
    "                        \"source\": rel['source_entity'],\n",
    "                        \"target\": rel['target_entity']\n",
    "                    })\n",
    "\n",
    "            count_rels = 0\n",
    "            for r_type, batch_data in rels_by_type.items():\n",
    "                rel_query = f\"\"\"\n",
    "                UNWIND $batch AS row\n",
    "                MATCH (source:Entity {{name: row.source}})\n",
    "                MATCH (target:Entity {{name: row.target}})\n",
    "                MERGE (source)-[:{r_type}]->(target)\n",
    "                \"\"\"\n",
    "                \n",
    "                batch_size = 1000\n",
    "                for i in range(0, len(batch_data), batch_size):\n",
    "                    chunk = batch_data[i:i + batch_size]\n",
    "                    session.run(rel_query, batch=chunk)\n",
    "                    count_rels += len(chunk)\n",
    "                    \n",
    "            print(f\"   ğŸ”— ê´€ê³„ ì—°ê²° ì™„ë£Œ (@{target_db}, {count_rels}ê±´)\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ [Error] '{target_db}' ë°ì´í„°ë² ì´ìŠ¤ ì ‘ì† ì‹¤íŒ¨: {e}\")\n",
    "        print(\"   (Tip: Enterprise ë²„ì „ì´ ì•„ë‹ˆê±°ë‚˜, DBê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. ë©”ì¸ ì‹¤í–‰ (Multi-Database Routing)\n",
    "# ==========================================\n",
    "def run_multidb_ingest(full_df):\n",
    "    # ë“œë¼ì´ë²„ëŠ” í•œ ë²ˆë§Œ ì—°ê²°\n",
    "    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))\n",
    "    \n",
    "    # ë“œë¼ì´ë²„ ì—°ê²° í™•ì¸\n",
    "    try:\n",
    "        driver.verify_connectivity()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Neo4j ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "        return\n",
    "\n",
    "    # ì‹¤í—˜ ëª¨ë“œë³„ë¡œ ë°ì´í„° ë¶„ë¦¬ ë° ì ì¬\n",
    "    modes = full_df['experiment_mode'].unique()\n",
    "    print(f\"ğŸ” ê°ì§€ëœ ì‹¤í—˜ ëª¨ë“œ: {modes}\")\n",
    "    \n",
    "    for mode in modes:\n",
    "        if mode not in DB_MAPPING:\n",
    "            print(f\"âš ï¸ ê²½ê³ : ëª¨ë“œ '{mode}'ì— ë§¤í•‘ëœ DBê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "            continue\n",
    "            \n",
    "        target_db_name = DB_MAPPING[mode]\n",
    "        subset_df = full_df[full_df['experiment_mode'] == mode]\n",
    "        \n",
    "        # í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ë“œë¼ì´ë²„ë¥¼ ì¬ì‚¬ìš©\n",
    "        ingest_to_specific_db(driver, subset_df, mode, target_db_name)\n",
    "\n",
    "    driver.close()\n",
    "    print(\"\\nğŸ‰ ëª¨ë“  ë°ì´í„° ì ì¬ ì™„ë£Œ!\")\n",
    "\n",
    "if 'kgcandid' in locals():\n",
    "        run_multidb_ingest(kgcandid)\n",
    "else:\n",
    "        print(\"âš ï¸ 'kgcandid' ë°ì´í„°í”„ë ˆì„ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "df = pd.read_parquet(\"hf://datasets/Linq-AI-Research/FinDER/data/train-00000-of-00001.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df[\n",
    "        (df['type'].notnull()) & \n",
    "        (df['type'] != 'None') & \n",
    "        (df['type'] != '')\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Impact of non-op adjustments on OI to IBT transition for FY23, ticker in last position.',\n",
       " 'Tyson Foods global workforce, ticker TSN, shows a contrast between the US vs ex-US.',\n",
       " 'GPM (Gross Profit/Net Revenues) FY23 ENPH.',\n",
       " 'Total calc for DaVita pro dev cost per emp.',\n",
       " \"NVR's headcount decline in 2022 & 2023.\",\n",
       " 'Trend in basic EPS for SBUX over three FYs shows profitability.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[text for text in clean_df.groupby('type').sample(1).text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
