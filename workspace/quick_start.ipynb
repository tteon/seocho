{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82b72a52",
   "metadata": {},
   "source": [
    "# Quick Start: Opik + OpenAI + DotEnv\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load environment variables using `python-dotenv`.\n",
    "2. Initialize OpenAI client.\n",
    "3. Integrate Opik for tracing.\n",
    "4. Use Opik for Prompt Management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff6bbeae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded.\n"
     ]
    }
   ],
   "source": [
    "# 1. Environment Setup\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment variables loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ea20d0-441c-43d3-96ab-7a395ea961b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476fefa2-0491-47aa-b57e-2f042e6ff664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your Opik instance URL: http://localhost:5173/default/home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Opik is not accessible at http://localhost:5173/. Please try again, the URL should follow a format similar to http://localhost:5173/\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your Opik instance URL: http://localhost:5173/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Opik is not accessible at http://localhost:5173/. Please try again, the URL should follow a format similar to http://localhost:5173/\n"
     ]
    }
   ],
   "source": [
    "import opik\n",
    "\n",
    "opik.configure(use_local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2457864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opik URL: None\n",
      "Opik configured and OpenAI client wrapped.\n"
     ]
    }
   ],
   "source": [
    "# 2. Opik Setup & Tracing\n",
    "import opik\n",
    "from opik.integrations.openai import track_openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# Ensure Opik points to the host instance (using the URL override from docker-compose)\n",
    "# docker-compose.yml sets OPIK_URL_OVERRIDE=http://host.docker.internal:5173/api\n",
    "# We can verify this:\n",
    "print(f\"Opik URL: {os.getenv('OPIK_URL_OVERRIDE')}\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "# Wrap the client with Opik tracker\n",
    "openai_client = track_openai(client)\n",
    "\n",
    "print(\"Opik configured and OpenAI client wrapped.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run a Trace\n",
    "try:\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Write a haiku about observability.\"}\n",
    "        ]\n",
    "    )\n",
    "    print(\"\\nResponse:\")\n",
    "    print(completion.choices[0].message.content)\n",
    "    print(\"\\nCheck your Opik dashboard for the trace!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error making request: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd77d03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Prompt Management\n",
    "try:\n",
    "    # Create or retrieve a prompt\n",
    "    prompt_name = \"observability-story-1\"\n",
    "    prompt_template = \"Write a short story about {{topic}} using {{adjective}} language.\"\n",
    "    \n",
    "    prompt = opik.Prompt(\n",
    "        name=prompt_name,\n",
    "        prompt=prompt_template\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nPrompt '{prompt.name}' created/retrieved.\")\n",
    "    print(f\"Template: {prompt.prompt}\")\n",
    "    \n",
    "    # Format the prompt\n",
    "    formatted_prompt = prompt.format(topic=\"AI agents\", adjective=\"flowery\")\n",
    "    print(f\"\\nFormatted Prompt:\\n{formatted_prompt}\")\n",
    "    \n",
    "    # Use the formatted prompt in a call (traced)\n",
    "    completion = openai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nStory Response:\")\n",
    "    print(completion.choices[0].message.content)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error in prompt management: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
